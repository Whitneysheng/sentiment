{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import docx2txt\n",
    "import gensim\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = docx2txt.process(\"test.docx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens=tokenizer.tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_words=[tokens]\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=40) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=40)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "new_set=['etc','activity',,'note','call','meeting','author','strategy','strategies','fund','lp','long','short',\n",
    "        'manager','type','market','markets','vs','said','would','since','within','across','ytd','time','month','year',\n",
    "         'article','according','get','go','mtd','gp','dm','author_effective_date_activity','e_g','absolute_return_institutional','fund_lp',\n",
    "        'absolute','return_institutional_fund_lp','2019_sector_multi_strategy','sub_strategy','non_pass_through_rv',\n",
    "        'multi_strategy','strategy_relative_value','absolute_return','research','30_2019_sector_multi','stock_selection','update','business','use','look','need']\n",
    "stop_words.update(new_set)\n",
    "factor_asset=['multi', 'value', 'return', 'risk', 'absolute', 'rv', 'non', 'relative', 'institutional', 'sub', 'sector', 'pass', 'equity', 'stock', 'selection', 'gaa', 'data', 'developed', 'global', 'date', 'performance', 'gross', 'effective', 'futures', 'arbitrage', 'management', 'trading', 'date', 'performance', 'gross', 'effective', 'futures', 'arbitrage', 'management', \n",
    "              'office','e','trading','g','etc','qtd','aum','nav','end','bn','billion','q1','q2','q3','q4','team','us','em','emerging','developed','looking','firm','fixed','income','credit','also','fx','bond','go','going','likely','like']\n",
    "month=['jan','january','feb','february','mar','march','apr','april','may','jun','june','jul','july','aug','august','sep','sept','september','oct','october','nov','november','dec','december']\n",
    "number=['first','two','three','one']\n",
    "stop_words.update(factor_asset)\n",
    "stop_words.update(month)\n",
    "stop_words.update(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri=trigram_mod[bigram_mod[data_words]]\n",
    "\n",
    "data_lemmatized = lemmatization(tri, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "tokens=[x for sublist in data_lemmatized for x in sublist]\n",
    "tokens=[x.casefold() for x in tokens]\n",
    "stopped = [w for w in tokens if not w in stop_words]\n",
    "nonum=[item for item in stopped if not item.isdigit()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq = nltk.FreqDist(nonum)\n",
    "for key,val in freq.items():\n",
    "    print(str(key) + ':' + str(val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq.plot(20, cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import gensim.corpora as corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "# Build LDA model\n",
    "data_ready = [nonum]\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=1, \n",
    "                                           random_state=30,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=10,\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "print(lda_model.print_topics())\n",
    "\n",
    "\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
